@ARTICLE{mmwavesensingfire,
  author={Schenkel, Francesca and Schultze, Thorsten and Baer, Christoph and Rolfes, Ilona and Schulz, Christian},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Radar-Enabled Millimeter-Wave Sensing of Fire Interactions}, 
  year={2024},
  volume={73},
  number={},
  pages={1-10},
  keywords={Combustion;Radar;Fires;Permittivity;Electromagnetic scattering;Permittivity measurement;Atmospheric measurements;Combustion;fire meteorology;gas permittivity;radar measurements},
  doi={10.1109/TIM.2024.3400306}
},
@Article{wsnfire,
AUTHOR = {Yan, Xiaofei and Cheng, Hong and Zhao, Yandong and Yu, Wenhua and Huang, Huan and Zheng, Xiaoliang},
TITLE = {Real-Time Identification of Smoldering and Flaming Combustion Phases in Forest Using a Wireless Sensor Network-Based Multi-Sensor System and Artificial Neural Network},
JOURNAL = {Sensors},
VOLUME = {16},
YEAR = {2016},
NUMBER = {8},
ARTICLE-NUMBER = {1228},
URL = {https://www.mdpi.com/1424-8220/16/8/1228},
PubMedID = {27527175},
ISSN = {1424-8220},
ABSTRACT = {Diverse sensing techniques have been developed and combined with machine learning method for forest fire detection, but none of them referred to identifying smoldering and flaming combustion phases. This study attempts to real-time identify different combustion phases using a developed wireless sensor network (WSN)-based multi-sensor system and artificial neural network (ANN). Sensors (CO, CO2, smoke, air temperature and relative humidity) were integrated into one node of WSN. An experiment was conducted using burning materials from residual of forest to test responses of each node under no, smoldering-dominated and flaming-dominated combustion conditions. The results showed that the five sensors have reasonable responses to artificial forest fire. To reduce cost of the nodes, smoke, CO2 and temperature sensors were chiefly selected through correlation analysis. For achieving higher identification rate, an ANN model was built and trained with inputs of four sensor groups: smoke; smoke and CO2; smoke and temperature; smoke, CO2 and temperature. The model test results showed that multi-sensor input yielded higher predicting accuracy (≥82.5%) than single-sensor input (50.9%–92.5%). Based on these, it is possible to reduce the cost with a relatively high fire identification rate and potential application of the system can be tested in future under real forest condition.},
DOI = {10.3390/s16081228}
},
@article{MohapatraAnkita2022EWDT,
abstract = {As fires grow in intensity and frequency each year, so has the resistance from their anthropic victims in the form of firefighting technology and research. Although it is impossible to completely prevent wildfires, the potential devastation can be minimized if fires are detected and precisely geolocated while still in their nascent phases. Furthermore, automated approaches without human involvement are comparatively more efficient, accurate and capable of monitoring extremely remote and vast areas. With this specific intention, many research groups have proposed numerous approaches in the last several years, which can be grouped broadly into these four distinct categories: sensor nodes, unmanned aerial vehicles, camera networks and satellite surveillance. This review paper discusses notable advancements and trends in these categories, with subsequent shortcomings and challenges. We also describe a technical overview of common prototypes and several analysis models used to diagnose a fire from the raw input data. By writing this paper, we hoped to create a synopsis of the current state of technology in this emergent research area and provide a reference for further developments to other interested researchers.},
author = {Mohapatra, Ankita and Trinh, Timothy},
address = {Basel},
copyright = {COPYRIGHT 2022 MDPI AG},
issn = {2071-1050},
journal = {Sustainability},
keywords = {Drone aircraft ; Forest & brush fires ; Greenhouse gases ; Humidity ; Prototypes ; Remote monitoring ; Satellites ; Sensors ; Technology ; Trends ; Unmanned aerial vehicles ; Variables ; Wildfires},
language = {eng},
number = {19},
pages = {12270-},
publisher = {MDPI AG},
title = {Early Wildfire Detection Technologies in Practice—A Review},
volume = {14},
year = {2022},
},
@Article{wsnyolo,
author={Talaat, Fatma M.
and ZainEldin, Hanaa},
title={An improved fire detection approach based on YOLO-v8 for smart cities},
journal={Neural Computing and Applications},
year={2023},
month={Oct},
day={01},
volume={35},
number={28},
pages={20939-20954},
abstract={Fires in smart cities can have devastating consequences, causing damage to property, and endangering the lives of citizens. Traditional fire detection methods have limitations in terms of accuracy and speed, making it challenging to detect fires in real time. This paper proposes an improved fire detection approach for smart cities based on the YOLOv8 algorithm, called the smart fire detection system (SFDS), which leverages the strengths of deep learning to detect fire-specific features in real time. The SFDS approach has the potential to improve the accuracy of fire detection, reduce false alarms, and be cost-effective compared to traditional fire detection methods. It can also be extended to detect other objects of interest in smart cities, such as gas leaks or flooding. The proposed framework for a smart city consists of four primary layers: (i) Application layer, (ii) Fog layer, (iii) Cloud layer, and (iv) IoT layer. The proposed algorithm utilizes Fog and Cloud computing, along with the IoT layer, to collect and process data in real time, enabling faster response times and reducing the risk of damage to property and human life. The SFDS achieved state-of-the-art performance in terms of both precision and recall, with a high precision rate of 97.1{\%} for all classes. The proposed approach has several potential applications, including fire safety management in public areas, forest fire monitoring, and intelligent security systems.},
issn={1433-3058},
doi={10.1007/s00521-023-08809-1},
url={https://doi.org/10.1007/s00521-023-08809-1}
},
@article{kaimmwave,
abstract = {The boundaries of tracking and sensing solutions are continuously being pushed. A stimulation in this field over recent years is exploiting the properties of millimeter wave (mmWave) radar to achieve simultaneous tracking and sensing of multiple objects. This paper aims to provide a critical analysis of the current literature surrounding multi-object tracking and sensing with short-range mmWave radar. There is significant literature available regarding single-object tracking using mmWave radar, demonstrating the maturity of single-object tracking systems. However, innovative research and advancements are also needed in the field of mmWave radar multi-object tracking, specifically with respect to uniquely identifying multiple target tracks across an interrupted field of view. In this article, we aim to provide an overview of the latest progress in multi-target tracking. In particular, an attempt to phrase the problem space is made by firstly defining a typical multi-object tracking architecture. We then highlight the areas for potential advancements. These areas include sensor fusion, micro-Doppler feature analysis, specialized and generalized activity recognition, gait, tagging and shape profile. Potential multi-object tracking advancements are reviewed and compared with respect to adaptability, performance, accuracy and specificity. Although the majority of the literature reviewed has a focus on human targets, most of the methodologies can be applied to targets consisting of different profiles and characteristics to that of humans. Lastly, future research directions are also discussed to shed light on research opportunities and potential approaches in the open research areas.},
author = {Pearce, Andre and Zhang, J. Andrew and Xu, Richard and Wu, Kai},
address = {Basel},
copyright = {2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {2079-9292},
journal = {Electronics (Basel)},
keywords = {Activity recognition ; Antennas ; Gait recognition ; Millimeter waves ; Multiple target tracking ; Object recognition ; Radar systems ; Radar tracking ; Tracking ; Tracking systems},
language = {eng},
number = {2},
pages = {308-},
publisher = {MDPI AG},
title = {Multi-Object Tracking with mmWave Radar: A Review},
volume = {12},
year = {2023},
},
@Article{prepfire,
AUTHOR = {Ryu, Jinkyu and Kwak, Dongkurl},
TITLE = {A Study on a Complex Flame and Smoke Detection Method Using Computer Vision Detection and Convolutional Neural Network},
JOURNAL = {Fire},
VOLUME = {5},
YEAR = {2022},
NUMBER = {4},
ARTICLE-NUMBER = {108},
URL = {https://www.mdpi.com/2571-6255/5/4/108},
ISSN = {2571-6255},
ABSTRACT = {This study sought an effective detection method not only for flame but also for the smoke generated in the event of a fire. To this end, the flame region was pre-processed using the color conversion and corner detection method, and the smoke region could be detected using the dark channel prior and optical flow. This eliminates unnecessary background regions and allows selection of fire-related regions. Where there was a pre-processed region of interest, inference was conducted using a deep-learning-based convolutional neural network (CNN) to accurately determine whether it was a flame or smoke. Through this approach, the detection accuracy is improved by 5.5% for flame and 6% for smoke compared to when a fire is detected through the object detection model without separate pre-processing.},
DOI = {10.3390/fire5040108}
},
@InProceedings{uav,
author="Afghah, Fatemeh",
editor="Blasch, Erik
and Darema, Frederica
and Aved, Alex",
title="Autonomous Unmanned Aerial Vehicle Systems in Wildfire Detection and Management-Challenges and Opportunities",
booktitle="Dynamic Data Driven Applications Systems",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="386--394",
abstract="Wildfires are one of the costliest and deadliest natural disasters in the United States, particularly in the Western USA. Wildfire frequency and severity are increasing due to climate change and urban sprawl. Detecting forest fires at early stages enhances the chance of in-time intervention and efficient fire management and evacuation strategies. Forest fires are commonly detected by sensor systems that are not widely available across the nation or using satellite images that offer global coverage but suffer from low temporal and spatial resolution, resulting in missing the forest fires in the early stages. Unmanned aerial systems (UAS) have been recently utilized for this purpose, noting their accessibility and low deployment cost. In this paper, we present some recent advances in drone-based fire detection and discuss current challenges toward a wide-scale deployment.",
isbn="978-3-031-52670-1"
},
@Article{satellite,
AUTHOR = {Thangavel, Kathiravan and Spiller, Dario and Sabatini, Roberto and Amici, Stefania and Sasidharan, Sarathchandrakumar Thottuchirayil and Fayek, Haytham and Marzocca, Pier},
TITLE = {Autonomous Satellite Wildfire Detection Using Hyperspectral Imagery and Neural Networks: A Case Study on Australian Wildfire},
JOURNAL = {Remote Sensing},
VOLUME = {15},
YEAR = {2023},
NUMBER = {3},
ARTICLE-NUMBER = {720},
URL = {https://www.mdpi.com/2072-4292/15/3/720},
ISSN = {2072-4292},
ABSTRACT = {One of the United Nations (UN) Sustainable Development Goals is climate action (SDG-13), and wildfire is among the catastrophic events that both impact climate change and are aggravated by it. In Australia and other countries, large-scale wildfires have dramatically grown in frequency and size in recent years. These fires threaten the world’s forests and urban woods, cause enormous environmental and property damage, and quite often result in fatalities. As a result of their increasing frequency, there is an ongoing debate over how to handle catastrophic wildfires and mitigate their social, economic, and environmental repercussions. Effective prevention, early warning, and response strategies must be well-planned and carefully coordinated to minimise harmful consequences to people and the environment. Rapid advancements in remote sensing technologies such as ground-based, aerial surveillance vehicle-based, and satellite-based systems have been used for efficient wildfire surveillance. This study focuses on the application of space-borne technology for very accurate fire detection under challenging conditions. Due to the significant advances in artificial intelligence (AI) techniques in recent years, numerous studies have previously been conducted to examine how AI might be applied in various situations. As a result of its special physical and operational requirements, spaceflight has emerged as one of the most challenging application fields. This work contains a feasibility study as well as a model and scenario prototype for a satellite AI system. With the intention of swiftly generating alerts and enabling immediate actions, the detection of wildfires has been studied with reference to the Australian events that occurred in December 2019. Convolutional neural networks (CNNs) were developed, trained, and used from the ground up to detect wildfires while also adjusting their complexity to meet onboard implementation requirements for trusted autonomous satellite operations (TASO). The capability of a 1-dimensional convolution neural network (1-DCNN) to classify wildfires is demonstrated in this research and the results are assessed against those reported in the literature. In order to enable autonomous onboard data processing, various hardware accelerators were considered and evaluated for onboard implementation. The trained model was then implemented in the following: Intel Movidius NCS-2 and Nvidia Jetson Nano and Nvidia Jetson TX2. Using the selected onboard hardware, the developed model was then put into practice and analysis was carried out. The results were positive and in favour of using the technology that has been proposed for onboard data processing to enable TASO on future missions. The findings indicate that data processing onboard can be very beneficial in disaster management and climate change mitigation by facilitating the generation of timely alerts for users and by enabling rapid and appropriate responses.},
DOI = {10.3390/rs15030720}
},
@article{uavai,
abstract = {Wildfires are a worldwide natural disaster causing important economic damages and loss of lives. Experts predict that wildfires will increase in the coming years mainly due to climate change. Early detection and prediction of fire spread can help reduce affected areas and improve firefighting. Numerous systems were developed to detect fire. Recently, Unmanned Aerial Vehicles were employed to tackle this problem due to their high flexibility, their low-cost, and their ability to cover wide areas during the day or night. However, they are still limited by challenging problems such as small fire size, background complexity, and image degradation. To deal with the aforementioned limitations, we adapted and optimized Deep Learning methods to detect wildfire at an early stage. A novel deep ensemble learning method, which combines EfficientNet-B5 and DenseNet-201 models, is proposed to identify and classify wildfire using aerial images. In addition, two vision transformers (TransUNet and TransFire) and a deep convolutional model (EfficientSeg) were employed to segment wildfire regions and determine the precise fire regions. The obtained results are promising and show the efficiency of using Deep Learning and vision transformers for wildfire classification and segmentation. The proposed model for wildfire classification obtained an accuracy of 85.12% and outperformed many state-of-the-art works. It proved its ability in classifying wildfire even small fire areas. The best semantic segmentation models achieved an F1-score of 99.9% for TransUNet architecture and 99.82% for TransFire architecture superior to recent published models. More specifically, we demonstrated the ability of these models to extract the finer details of wildfire using aerial images. They can further overcome current model limitations, such as background complexity and small wildfire areas.},
author = {Ghali, Rafik and Akhloufi, Moulay A and Mseddi, Wided Souidene},
address = {Switzerland},
copyright = {2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {1424-8220},
journal = {Sensors (Basel, Switzerland)},
keywords = {Accuracy ; aerial images ; Classification ; Climate Change ; Complexity ; Deep Learning ; fire classification ; fire segmentation ; Fires ; Forest & brush fires ; Image classification ; Image degradation ; Methods ; Natural disasters ; Sensors ; UAV ; Unmanned aerial vehicles ; vision transformers ; wildfire detection ; Wildfires},
language = {eng},
number = {5},
pages = {1977-},
publisher = {MDPI AG},
title = {Deep Learning and Transformer Approaches for UAV-Based Wildfire Detection and Segmentation},
volume = {22},
year = {2022},
},
@misc{dataenriching,
      title={Enriching Neural Network Training Dataset to Improve Worst-Case Performance Guarantees}, 
      author={Rahul Nellikkath and Spyros Chatzivasileiadis},
      year={2023},
      eprint={2303.13228},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2303.13228}, 
},
@article{transferlearning,
abstract = {Coronavirus disease (COVID‐19) is a pandemic that has caused thousands of casualties and impacts all over the world. Most countries are facing a shortage of COVID‐19 test kits in hospitals due to the daily increase in the number of cases. Early detection of COVID‐19 can protect people from severe infection. Unfortunately, COVID‐19 can be misdiagnosed as pneumonia or other illness and can lead to patient death. Therefore, in order to avoid the spread of COVID‐19 among the population, it is necessary to implement an automated early diagnostic system as a rapid alternative diagnostic system. Several researchers have done very well in detecting COVID‐19; however, most of them have lower accuracy and overfitting issues that make early screening of COVID‐19 difficult. Transfer learning is the most successful technique to solve this problem with higher accuracy. In this paper, we studied the feasibility of applying transfer learning and added our own classifier to automatically classify COVID‐19 because transfer learning is very suitable for medical imaging due to the limited availability of data. In this work, we proposed a CNN model based on deep transfer learning technique using six different pre‐trained architectures, including VGG16, DenseNet201, MobileNetV2, ResNet50, Xception, and EfficientNetB0. A total of 3886 chest X‐rays (1200 cases of COVID‐19, 1341 healthy and 1345 cases of viral pneumonia) were used to study the effectiveness of the proposed CNN model. A comparative analysis of the proposed CNN models using three classes of chest X‐ray datasets was carried out in order to find the most suitable model. Experimental results show that the proposed CNN model based on VGG16 was able to accurately diagnose COVID‐19 patients with 97.84% accuracy, 97.90% precision, 97.89% sensitivity, and 97.89% of F1‐score. Evaluation of the test data shows that the proposed model produces the highest accuracy among CNNs and seems to be the most suitable choice for COVID‐19 classification. We believe that in this pandemic situation, this model will support healthcare professionals in improving patient screening.},
author = {Asif, Sohaib and Wenhui, Yi and Amjad, Kamran and Jin, Hou and Tao, Yi and Jinhai, Si},
address = {England},
copyright = {2022 John Wiley & Sons Ltd.},
issn = {0266-4720},
journal = {Expert systems},
keywords = {Accuracy ; Artificial neural networks ; Casualties ; chest X‐rays ; COVID-19 ; COVID‐19 detection ; deep CNN ; Diagnostic systems ; Machine learning ; medical image analysis ; Medical imaging ; Original ; Pandemics ; Pneumonia ; transfer learning ; VGG16 ; Viral diseases},
language = {eng},
number = {1},
publisher = {Blackwell Publishing Ltd},
title = {Detection of COVID‐19 from chest X‐ray images: Boosting the performance with convolutional neural network and transfer learning},
volume = {40},
year = {2023},
},
@inproceedings{SimardP.Y.2003Bpfc,
author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
booktitle = {Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings},
isbn = {9780769519609},
keywords = {Best practices ; Concrete ; Convolution ; Handwriting recognition ; Industrial training ; Information processing ; Neural networks ; Performance analysis ; Support vector machines ; Text analysis},
language = {eng},
pages = {958-963},
publisher = {IEEE},
title = {Best practices for convolutional neural networks applied to visual document analysis},
year = {2003},
},
@inproceedings{augment,
abstract = {In this paper we investigate the benefit of augmenting data with synthetically created samples when training a machine learning classifier. Two approaches for creating additional training samples are data warping, which generates additional samples through transformations applied in the data-space, and synthetic over-sampling, which creates additional samples in feature-space. We experimentally evaluate the benefits of data augmentation for a convolutional backpropagation-trained neural network, a convolutional support vector machine and a convolutional extreme learning machine classifier, using the standard MNIST handwritten digit dataset. We found that while it is possible to perform generic augmentation in feature-space, if plausible transforms for the data are known then augmentation in data-space provides a greater benefit for improving performance and reducing overfitting.},
author = {Wong, Sebastien C. and Gatt, Adam and Stamatescu, Victor and McDonnell, Mark D.},
booktitle = {2016 International Conference on Digital Image Computing: Techniques and Applications (DICTA)},
isbn = {9781509028962},
keywords = {Australia ; Neural networks ; Neurons ; Support vector machines ; Training ; Training data},
language = {eng},
pages = {1-6},
publisher = {IEEE},
title = {Understanding Data Augmentation for Classification: When to Warp?},
year = {2016},
},
@inproceedings{skinhsv,
abstract = {Since color is unaffected by scaling, rotation, or partial occlusion, it is an effective function for object detection. The identification of skin color is an essential stage in an eclectic range of computer vision applications. The rapidly expanding field of detecting human skin is focused on the idea that colored images can be used to collect details concerning individuals, mode, purpose, and image contents, and computers can then react appropriately. Skin color of humans can differ significantly in manifestation due to variety of aspects such as lighting, ethnicity, ageing, imaging conditions, as well as complex context, making human skin detection in complex images a difficult issue. Many techniques, on the other hand, have been created to deal with the issue of skin identification in color photographs. The skin detection algorithm proposed in this research paper is based on thresholding HSV color model bands with upper and lower bounds to create a correct mask, which is then logically ANDed with the original image to restore the skin tone pixels. For images taken in the natural world and under various illuminations and light conditions, the experimental results showed 99.135 percent precision and 99.587 percent accuracy.},
author = {Hassan, Enas Kh and Saud, Jamila Harbi},
address = {Melville},
booktitle = {AIP Conference Proceedings},
copyright = {Author(s)},
issn = {0094-243X},
keywords = {Aging (natural) ; Algorithms ; Color ; Computer vision ; Image restoration ; Lower bounds ; Object recognition ; Occlusion ; Skin},
language = {eng},
number = {1},
publisher = {American Institute of Physics},
title = {HSV color model and logical filter for human skin detection},
volume = {2457},
year = {2023},
},
@article{harriscorner,
    title   = {{An Analysis and Implementation of the Harris Corner Detector}},
    author  = {Sánchez, Javier and Monzón, Nelson and Salgado, Agustín},
    journal = {{Image Processing On Line}},
    volume  = {8},
    pages   = {305--328},
    year    = {2018},
    note    = {\url{https://doi.org/10.5201/ipol.2018.229}}
},
@article{darkchannelprior,
abstract = {In this paper, we propose a simple but effective image prior-dark channel prior to remove haze from a single input image. The dark channel prior is a kind of statistics of outdoor haze-free images. It is based on a key observation-most local patches in outdoor haze-free images contain some pixels whose intensity is very low in at least one color channel. Using this prior with the haze imaging model, we can directly estimate the thickness of the haze and recover a high-quality haze-free image. Results on a variety of hazy images demonstrate the power of the proposed prior. Moreover, a high-quality depth map can also be obtained as a byproduct of haze removal.},
author = {He, Kaiming and Sun, Jian and Tang, Xiaoou},
address = {United States},
copyright = {Copyright The Institute of Electrical and Electronics Engineers, Inc. (IEEE) Dec 2011},
issn = {0162-8828},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Atmospheric modeling ; Byproducts ; Channel estimation ; Channels ; Color ; defog ; Dehaze ; depth estimation ; Haze ; Image color analysis ; Image restoration ; Outdoor ; Pattern analysis ; Statistics},
language = {eng},
number = {12},
pages = {2341-2353},
publisher = {IEEE},
title = {Single Image Haze Removal Using Dark Channel Prior},
volume = {33},
year = {2011},
},
@ARTICLE{dcpsmoke,

  author={Liu, Yanbei and Qin, Wen and Liu, Kaihua and Zhang, Fang and Xiao, Zhitao},

  journal={IEEE Access}, 

  title={A Dual Convolution Network Using Dark Channel Prior for Image Smoke Classification}, 

  year={2019},

  volume={7},

  number={},

  pages={60697-60706},

  keywords={Feature extraction;Fires;Image color analysis;Deep learning;Image edge detection;Data mining;Fuses;Dark channel prior;dual convolution network;image smoke classification;AlexNet},

  doi={10.1109/ACCESS.2019.2915599}}
