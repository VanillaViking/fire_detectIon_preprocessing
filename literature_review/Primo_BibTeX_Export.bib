@article{GhaliRafik2022DLaT,
abstract = {Wildfires are a worldwide natural disaster causing important economic damages and loss of lives. Experts predict that wildfires will increase in the coming years mainly due to climate change. Early detection and prediction of fire spread can help reduce affected areas and improve firefighting. Numerous systems were developed to detect fire. Recently, Unmanned Aerial Vehicles were employed to tackle this problem due to their high flexibility, their low-cost, and their ability to cover wide areas during the day or night. However, they are still limited by challenging problems such as small fire size, background complexity, and image degradation. To deal with the aforementioned limitations, we adapted and optimized Deep Learning methods to detect wildfire at an early stage. A novel deep ensemble learning method, which combines EfficientNet-B5 and DenseNet-201 models, is proposed to identify and classify wildfire using aerial images. In addition, two vision transformers (TransUNet and TransFire) and a deep convolutional model (EfficientSeg) were employed to segment wildfire regions and determine the precise fire regions. The obtained results are promising and show the efficiency of using Deep Learning and vision transformers for wildfire classification and segmentation. The proposed model for wildfire classification obtained an accuracy of 85.12% and outperformed many state-of-the-art works. It proved its ability in classifying wildfire even small fire areas. The best semantic segmentation models achieved an F1-score of 99.9% for TransUNet architecture and 99.82% for TransFire architecture superior to recent published models. More specifically, we demonstrated the ability of these models to extract the finer details of wildfire using aerial images. They can further overcome current model limitations, such as background complexity and small wildfire areas.},
author = {Ghali, Rafik and Akhloufi, Moulay A and Mseddi, Wided Souidene},
address = {Switzerland},
copyright = {2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
issn = {1424-8220},
journal = {Sensors (Basel, Switzerland)},
keywords = {Accuracy ; aerial images ; Classification ; Climate Change ; Complexity ; Deep Learning ; fire classification ; fire segmentation ; Fires ; Forest & brush fires ; Image classification ; Image degradation ; Methods ; Natural disasters ; Sensors ; UAV ; Unmanned aerial vehicles ; vision transformers ; wildfire detection ; Wildfires},
language = {eng},
number = {5},
pages = {1977-},
publisher = {MDPI AG},
title = {Deep Learning and Transformer Approaches for UAV-Based Wildfire Detection and Segmentation},
volume = {22},
year = {2022},
}

